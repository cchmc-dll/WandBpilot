{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ec7ff3",
   "metadata": {},
   "source": [
    "Copyright (c) MONAI Consortium\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ba3a8-1af8-43f9-bc82-1150526864c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d80ed2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import distutils.util\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c7d9a8f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "from monai.apps.deepedit.interaction import Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31801cc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.apps.deepedit.transforms import (\n",
    "    AddGuidanceSignalDeepEditd,\n",
    "    AddRandomGuidanceDeepEditd,\n",
    "    FindDiscrepancyRegionsDeepEditd,\n",
    "    NormalizeLabelsInDatasetd,\n",
    "    FindAllValidSlicesMissingLabelsd,\n",
    "    AddInitialSeedPointMissingLabelsd,\n",
    "    SplitPredsLabeld,\n",
    ")\n",
    "from monai.data import partition_dataset\n",
    "from monai.data.dataloader import DataLoader\n",
    "from monai.data.dataset import PersistentDataset\n",
    "from monai.engines import SupervisedEvaluator, SupervisedTrainer\n",
    "from monai.handlers import (\n",
    "    CheckpointSaver,\n",
    "    LrScheduleHandler,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    ValidationHandler,\n",
    "    from_engine,\n",
    ")\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.networks.nets import DynUNet, UNETR\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AddChanneld,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandShiftIntensityd,\n",
    "    RandRotate90d,\n",
    "    Resized,\n",
    "    ScaleIntensityRanged,\n",
    "    ToNumpyd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293a7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(network, labels, spatial_size):\n",
    "    # Network\n",
    "    if network == \"unetr\":\n",
    "        network = UNETR(\n",
    "            spatial_dims=3,\n",
    "            in_channels=len(labels) + 1,\n",
    "            out_channels=len(labels),\n",
    "            img_size=spatial_size,\n",
    "            feature_size=64,\n",
    "            hidden_size=1536,\n",
    "            mlp_dim=3072,\n",
    "            num_heads=48,\n",
    "            pos_embed=\"conv\",\n",
    "            norm_name=\"instance\",\n",
    "            res_block=True,\n",
    "        )\n",
    "    else:\n",
    "        network = DynUNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=len(labels) + 1,\n",
    "            out_channels=len(labels),\n",
    "            kernel_size=[3, 3, 3, 3, 3, 3],\n",
    "            strides=[1, 2, 2, 2, 2, [2, 2, 1]],\n",
    "            upsample_kernel_size=[2, 2, 2, 2, [2, 2, 1]],\n",
    "            norm_name=\"instance\",\n",
    "            deep_supervision=False,\n",
    "            res_block=True,\n",
    "        )\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5655410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_transforms(labels, spatial_size):\n",
    "    t = [\n",
    "        LoadImaged(keys=(\"image\", \"label\"), reader=\"ITKReader\"),\n",
    "        NormalizeLabelsInDatasetd(keys=\"label\", label_names=labels),\n",
    "        AddChanneld(keys=(\"image\", \"label\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # This transform may not work well for MR images\n",
    "        ScaleIntensityRanged(keys=\"image\", a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        RandFlipd(keys=(\"image\", \"label\"), spatial_axis=[0], prob=0.10),\n",
    "        RandFlipd(keys=(\"image\", \"label\"), spatial_axis=[1], prob=0.10),\n",
    "        RandFlipd(keys=(\"image\", \"label\"), spatial_axis=[2], prob=0.10),\n",
    "        RandRotate90d(keys=(\"image\", \"label\"), prob=0.10, max_k=3),\n",
    "        RandShiftIntensityd(keys=\"image\", offsets=0.10, prob=0.50),\n",
    "        Resized(keys=(\"image\", \"label\"), spatial_size=spatial_size, mode=(\"area\", \"nearest\")),\n",
    "        # Transforms for click simulation\n",
    "        FindAllValidSlicesMissingLabelsd(keys=\"label\", sids=\"sids\"),\n",
    "        AddInitialSeedPointMissingLabelsd(keys=\"label\", guidance=\"guidance\", sids=\"sids\"),\n",
    "        AddGuidanceSignalDeepEditd(keys=\"image\", guidance=\"guidance\"),\n",
    "        #\n",
    "        ToTensord(keys=(\"image\", \"label\")),\n",
    "    ]\n",
    "\n",
    "    return Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b42c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_click_transforms():\n",
    "    t = [\n",
    "        Activationsd(keys=\"pred\", softmax=True),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        ToNumpyd(keys=(\"image\", \"label\", \"pred\")),\n",
    "        # Transforms for click simulation\n",
    "        FindDiscrepancyRegionsDeepEditd(keys=\"label\", pred=\"pred\", discrepancy=\"discrepancy\"),\n",
    "        AddRandomGuidanceDeepEditd(\n",
    "            keys=\"NA\",\n",
    "            guidance=\"guidance\",\n",
    "            discrepancy=\"discrepancy\",\n",
    "            probability=\"probability\",\n",
    "        ),\n",
    "        AddGuidanceSignalDeepEditd(keys=\"image\", guidance=\"guidance\"),\n",
    "        #\n",
    "        ToTensord(keys=(\"image\", \"label\")),\n",
    "    ]\n",
    "\n",
    "    return Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22144fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_post_transforms(labels):\n",
    "    t = [\n",
    "        Activationsd(keys=\"pred\", softmax=True),\n",
    "        AsDiscreted(\n",
    "            keys=(\"pred\", \"label\"),\n",
    "            argmax=(True, False),\n",
    "            to_onehot=(len(labels), len(labels)),\n",
    "        ),\n",
    "        # This transform is to check dice score per segment/label\n",
    "        SplitPredsLabeld(keys=\"pred\"),\n",
    "    ]\n",
    "    return Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720c2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(args, pre_transforms):\n",
    "    multi_gpu = args.multi_gpu\n",
    "    local_rank = args.local_rank\n",
    "\n",
    "    all_images = sorted(glob.glob(os.path.join(args.input, \"*.nii.gz\")))\n",
    "    all_labels = sorted(glob.glob(os.path.join(args.input, \"labels\", \"final\", \"*.nii.gz\")))\n",
    "    datalist = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in\n",
    "                zip(all_images, all_labels)]\n",
    "\n",
    "    datalist = datalist[0: args.limit] if args.limit else datalist\n",
    "    total_l = len(datalist)\n",
    "\n",
    "    if multi_gpu:\n",
    "        datalist = partition_dataset(\n",
    "            data=datalist,\n",
    "            num_partitions=dist.get_world_size(),\n",
    "            even_divisible=True,\n",
    "            shuffle=True,\n",
    "            seed=args.seed,\n",
    "        )[local_rank]\n",
    "\n",
    "    train_datalist, val_datalist = partition_dataset(\n",
    "        datalist,\n",
    "        ratios=[args.split, (1 - args.split)],\n",
    "        shuffle=True,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "    \n",
    "    logging.info(\n",
    "        \"CACHE_DIR IS: {}\".format(\n",
    "            args.cache_dir\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    train_ds = PersistentDataset(\n",
    "        train_datalist, pre_transforms, cache_dir=args.cache_dir\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, shuffle=True, num_workers=2\n",
    "    )\n",
    "    logging.info(\n",
    "        \"{}:: Total Records used for Training is: {}/{}\".format(\n",
    "            local_rank, len(train_ds), total_l\n",
    "        )\n",
    "    )\n",
    "\n",
    "    val_ds = PersistentDataset(val_datalist, pre_transforms, cache_dir=args.cache_dir)\n",
    "    val_loader = DataLoader(val_ds, num_workers=2)\n",
    "    logging.info(\n",
    "        \"{}:: Total Records used for Validation is: {}/{}\".format(\n",
    "            local_rank, len(val_ds), total_l\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7092b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_trainer(args):\n",
    "\n",
    "    set_determinism(seed=args.seed)\n",
    "\n",
    "    multi_gpu = args.multi_gpu\n",
    "    local_rank = args.local_rank\n",
    "    if multi_gpu:\n",
    "        dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        device = torch.device(\"cuda:{}\".format(local_rank))\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n",
    "\n",
    "    pre_transforms = get_pre_transforms(args.labels, args.spatial_size)\n",
    "    click_transforms = get_click_transforms()\n",
    "    post_transform = get_post_transforms(args.labels)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(args, pre_transforms)\n",
    "\n",
    "    # define training components\n",
    "    network = get_network(args.network, args.labels, args.spatial_size).to(device)\n",
    "    if multi_gpu:\n",
    "        network = torch.nn.parallel.DistributedDataParallel(\n",
    "            network, device_ids=[local_rank], output_device=local_rank\n",
    "        )\n",
    "\n",
    "    if args.resume:\n",
    "        logging.info(\"{}:: Loading Network...\".format(local_rank))\n",
    "        map_location = {\"cuda:0\": \"cuda:{}\".format(local_rank)}\n",
    "        network.load_state_dict(\n",
    "            torch.load(args.model_filepath, map_location=map_location)\n",
    "        )\n",
    "\n",
    "    # define event-handlers for engine\n",
    "    val_handlers = [\n",
    "        StatsHandler(output_transform=lambda x: None),\n",
    "        TensorBoardStatsHandler(log_dir=args.output, output_transform=lambda x: None),\n",
    "        CheckpointSaver(\n",
    "            save_dir=args.output,\n",
    "            save_dict={\"net\": network},\n",
    "            save_key_metric=True,\n",
    "            save_final=True,\n",
    "            save_interval=args.save_interval,\n",
    "            final_filename=\"pretrained_deepedit_\" + args.network + \".pt\",\n",
    "        ),\n",
    "    ]\n",
    "    val_handlers = val_handlers if local_rank == 0 else None\n",
    "\n",
    "    all_val_metrics = dict()\n",
    "    all_val_metrics[\"val_mean_dice\"] = MeanDice(\n",
    "        output_transform=from_engine([\"pred\", \"label\"]), include_background=False\n",
    "    )\n",
    "    for key_label in args.labels:\n",
    "        if key_label != \"background\":\n",
    "            all_val_metrics[key_label + \"_dice\"] = MeanDice(\n",
    "                output_transform=from_engine([\"pred_\" + key_label, \"label_\" + key_label]), include_background=False\n",
    "            )\n",
    "\n",
    "    evaluator = SupervisedEvaluator(\n",
    "        device=device,\n",
    "        val_data_loader=val_loader,\n",
    "        network=network,\n",
    "        iteration_update=Interaction(\n",
    "            deepgrow_probability=args.deepgrow_probability_val,\n",
    "            transforms=click_transforms,\n",
    "            click_probability_key=\"probability\",\n",
    "            train=False,\n",
    "            label_names=args.labels,\n",
    "        ),\n",
    "        inferer=SimpleInferer(),\n",
    "        postprocessing=post_transform,\n",
    "        key_val_metric=all_val_metrics,\n",
    "        val_handlers=val_handlers,\n",
    "    )\n",
    "\n",
    "    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "    optimizer = torch.optim.Adam(network.parameters(), args.learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)\n",
    "\n",
    "    train_handlers = [\n",
    "        LrScheduleHandler(lr_scheduler=lr_scheduler, print_lr=True),\n",
    "        ValidationHandler(\n",
    "            validator=evaluator, interval=args.val_freq, epoch_level=True\n",
    "        ),\n",
    "        StatsHandler(\n",
    "            tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)\n",
    "        ),\n",
    "        TensorBoardStatsHandler(\n",
    "            log_dir=args.output,\n",
    "            tag_name=\"train_loss\",\n",
    "            output_transform=from_engine([\"loss\"], first=True),\n",
    "        ),\n",
    "        CheckpointSaver(\n",
    "            save_dir=args.output,\n",
    "            save_dict={\"net\": network, \"opt\": optimizer, \"lr\": lr_scheduler},\n",
    "            save_interval=args.save_interval * 2,\n",
    "            save_final=True,\n",
    "            final_filename=\"checkpoint.pt\",\n",
    "        ),\n",
    "    ]\n",
    "    train_handlers = train_handlers if local_rank == 0 else train_handlers[:2]\n",
    "\n",
    "    all_train_metrics = dict()\n",
    "    all_train_metrics[\"train_dice\"] = MeanDice(output_transform=from_engine([\"pred\", \"label\"]),\n",
    "                                               include_background=False)\n",
    "    for key_label in args.labels:\n",
    "        if key_label != \"background\":\n",
    "            all_train_metrics[key_label + \"_dice\"] = MeanDice(\n",
    "                output_transform=from_engine([\"pred_\" + key_label, \"label_\" + key_label]), include_background=False\n",
    "            )\n",
    "\n",
    "    trainer = SupervisedTrainer(\n",
    "        device=device,\n",
    "        max_epochs=args.epochs,\n",
    "        train_data_loader=train_loader,\n",
    "        network=network,\n",
    "        iteration_update=Interaction(\n",
    "            deepgrow_probability=args.deepgrow_probability_train,\n",
    "            transforms=click_transforms,\n",
    "            click_probability_key=\"probability\",\n",
    "            train=True,\n",
    "            label_names=args.labels,\n",
    "        ),\n",
    "        optimizer=optimizer,\n",
    "        loss_function=loss_function,\n",
    "        inferer=SimpleInferer(),\n",
    "        postprocessing=post_transform,\n",
    "        amp=args.amp,\n",
    "        key_train_metric=all_train_metrics,\n",
    "        train_handlers=train_handlers,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6371066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    if args.local_rank == 0:\n",
    "        for arg in vars(args):\n",
    "            logging.info(\"USING:: {} = {}\".format(arg, getattr(args, arg)))\n",
    "        print(\"\")\n",
    "\n",
    "    if args.export:\n",
    "        logging.info(\n",
    "            \"{}:: Loading PT Model from: {}\".format(args.local_rank, args.input)\n",
    "        )\n",
    "        device = torch.device(\"cuda\" if args.use_gpu else \"cpu\")\n",
    "        network = get_network(args.network, args.labels, args.spatial_size).to(device)\n",
    "\n",
    "        map_location = {\"cuda:0\": \"cuda:{}\".format(args.local_rank)}\n",
    "        network.load_state_dict(torch.load(args.input, map_location=map_location))\n",
    "\n",
    "        logging.info(\"{}:: Saving TorchScript Model\".format(args.local_rank))\n",
    "        model_ts = torch.jit.script(network)\n",
    "        torch.jit.save(model_ts, os.path.join(args.output))\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(args.output):\n",
    "        logging.info(\n",
    "            \"output path [{}] does not exist. creating it now.\".format(args.output)\n",
    "        )\n",
    "        os.makedirs(args.output, exist_ok=True)\n",
    "\n",
    "    trainer = create_trainer(args)\n",
    "\n",
    "    start_time = time.time()\n",
    "    trainer.run()\n",
    "    end_time = time.time()\n",
    "\n",
    "    logging.info(\"Total Training Time {}\".format(end_time - start_time))\n",
    "    if args.local_rank == 0:\n",
    "        logging.info(\"{}:: Saving Final PT Model\".format(args.local_rank))\n",
    "        torch.save(\n",
    "            trainer.network.state_dict(), os.path.join(args.output, \"pretrained_deepedit_\" + args.network + \"-final.pt\")\n",
    "        )\n",
    "\n",
    "    if not args.multi_gpu:\n",
    "        logging.info(\"{}:: Saving TorchScript Model\".format(args.local_rank))\n",
    "        model_ts = torch.jit.script(trainer.network)\n",
    "        torch.jit.save(model_ts, os.path.join(args.output, \"pretrained_deepedit_\" + args.network + \"-final.ts\"))\n",
    "\n",
    "    if args.multi_gpu:\n",
    "        dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf1f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strtobool(val):\n",
    "    return bool(distutils.util.strtobool(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a416ea-cbe5-41f0-8a0e-64894c63032e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optional Configuration Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3aabcef-2bde-4217-a56f-eccfd847fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Default Configuration for Abdominal Segmentation Project\n",
    "\n",
    "#define paths for dataset input / model output, output will make subfolders according to dataset name\n",
    "global config\n",
    "config = {}\n",
    "config['dataset_path'] = \"/workspace/abdominal-segmentation/datasets\"\n",
    "config['output_path'] = \"/workspace/abdominal-segmentation/models\"\n",
    "#custom arg variables\n",
    "config['dataset'] = \"Task09_Spleen/imagesTr\"\n",
    "\n",
    "config['input'] = config['dataset_path'] + \"/\" + config['dataset']\n",
    "config['output'] = config['output_path'] + \"/\" + config['dataset']\n",
    "config['epochs'] = 100\n",
    "config['multi_gpu'] = False\n",
    "config['network'] = \"dynunet\"\n",
    "#config['num_samples'] = 4\n",
    "#defaults\n",
    "# config['use_gpu_bool'] = \"true\"\n",
    "# config['seednum'] = 36\n",
    "# config['amp_bool'] = \"false\"\n",
    "# config['split_float'] = 0.9\n",
    "# config['limit_int'] = 0\n",
    "# config['cache_dir_str'] = None\n",
    "# config['resume_bool'] = \"false\"\n",
    "# config['val_freq_int'] = 1\n",
    "# config['learning_rate_float'] = 0.0001\n",
    "# config['max_train_inter_int'] = 15\n",
    "# config['max_val_inter_int'] = 5\n",
    "# config['deepgrow_prob_train_float'] = 0.4\n",
    "# config['deepgrow_prob_val_float'] = 1.0\n",
    "# config['save_interval_int'] = 3\n",
    "# config['image_interval_int'] = 1\n",
    "# config['local_rank_int'] = 0\n",
    "# config['export_bool'] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4329d61-ac37-4c9a-b3a2-ab841f743145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "os.chdir('/workspace/abdominal-segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2afe9240-853f-432e-851b-592a4a3e67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('configs/test.yaml', 'w') as outfile:\n",
    "#     yaml.dump(config, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd20844-ea23-4aa3-9e38-4c9130937d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['-f'] #+ ['-c'] + ['configs/test.yaml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33a6e418-6bbc-4b15-825a-49cb24ead3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_args(config,args=None):\n",
    "    #print(' Args: ', args)\n",
    "    if not args:\n",
    "        parser = argparse.ArgumentParser(description='Empty parser for config dict')\n",
    "        parser.add_argument('-dmy', '--dummy', action='store_true')\n",
    "        args = parser.parse_args()\n",
    "    for key,item in config.items():\n",
    "        args.__setattr__(key,item)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f0630d5-1619-418e-9e5b-2c6b7412e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():  \n",
    "    parser = argparse.ArgumentParser(description='Configuration file to run deepedit Training')\n",
    "    args = None\n",
    "    try:\n",
    "        parser.add_argument(\"-s\", \"--seed\", type=int, default=36)\n",
    "        parser.add_argument(\"-n\", \"--network\", default=\"dynunet\", choices=[\"dynunet\", \"unetr\"])\n",
    "        parser.add_argument(\n",
    "            \"-i\",\n",
    "            \"--input\",\n",
    "            default=\"/home/andres/Documents/workspace/Datasets/MSD_datasets/Task09_Spleen\",\n",
    "        )\n",
    "        parser.add_argument(\"-o\", \"--output\", default=\"output\")\n",
    "\n",
    "        parser.add_argument(\"-g\", \"--use_gpu\", type=strtobool, default=\"true\")\n",
    "        parser.add_argument(\"-a\", \"--amp\", type=strtobool, default=\"false\")\n",
    "\n",
    "        parser.add_argument(\"-e\", \"--epochs\", type=int, default=100)\n",
    "        parser.add_argument(\"-x\", \"--split\", type=float, default=0.9)\n",
    "        parser.add_argument(\"-t\", \"--limit\", type=int, default=0)\n",
    "        parser.add_argument(\"--cache_dir\", type=str, default=None)\n",
    "\n",
    "        parser.add_argument(\"-r\", \"--resume\", type=strtobool, default=\"false\")\n",
    "\n",
    "        parser.add_argument(\"-f\", \"--val_freq\", type=int, default=1)\n",
    "        parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=0.0001)\n",
    "        parser.add_argument(\"-it\", \"--max_train_interactions\", type=int, default=15)\n",
    "        parser.add_argument(\"-iv\", \"--max_val_interactions\", type=int, default=5)\n",
    "\n",
    "        parser.add_argument(\"-dpt\", \"--deepgrow_probability_train\", type=float, default=0.4)\n",
    "        parser.add_argument(\"-dpv\", \"--deepgrow_probability_val\", type=float, default=1.0)\n",
    "\n",
    "        parser.add_argument(\"--save_interval\", type=int, default=3)\n",
    "        parser.add_argument(\"--image_interval\", type=int, default=1)\n",
    "        parser.add_argument(\"--multi_gpu\", type=strtobool, default=\"false\")\n",
    "        parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "        parser.add_argument(\"--export\", type=strtobool, default=\"false\")\n",
    "\n",
    "        parser.add_argument(\"-c\",'--config',type=str, default=None)\n",
    "        args = parser.parse_args()\n",
    "    except:\n",
    "        print('Cannot successfuly parse commandline arguments!')\n",
    "\n",
    "    if args:\n",
    "        if args.config:\n",
    "            print('Configuration file path found, reading settings from file', args.config)\n",
    "            with open(args.config) as conf_file:\n",
    "                configf = yaml.safe_load(conf_file)\n",
    "            args = dict_to_args(config, args)\n",
    "        else:\n",
    "            try:\n",
    "                if 'config' in globals():\n",
    "                    print('Using Configuration settings defined in source file')\n",
    "                    args = dict_to_args(config,args)\n",
    "            except Exception as e:\n",
    "                print('No default configuration settings defined in source file')\n",
    "                print(e)\n",
    "\n",
    "    if args:\n",
    "        args.spatial_size = [128, 128, 128]\n",
    "        # # For multiple label using the BTCV dataset (https://www.synapse.org/#!Synapse:syn3193805/wiki/217789)\n",
    "        # # For this, remember to update accordingly the function 'get_loaders' in lines 151-152\n",
    "        args.labels = {\"spleen\": 1,\"background\": 0,}\n",
    "#         args.labels = {\n",
    "#                    \"liver\": 1,\n",
    "#                 #   \"right kidney\": 2,\n",
    "#                 #   \"left kidney\": 3,\n",
    "#                 #   \"gallbladder\": 4,\n",
    "#                 #   \"esophagus\": 5,\n",
    "#                    \"spleen\": 2,\n",
    "#                 #   \"stomach\": 7,\n",
    "#                 #   \"aorta\": 8,\n",
    "#                    \"background\": 0,\n",
    "#                  }\n",
    "        # Restoring previous model if resume flag is True\n",
    "        #args.model_filepath = args.output + \"/net_key_metric=0.8566.pt\"\n",
    "        print('Training started with these settings: ', args)\n",
    "        run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16663e56-252d-49c6-be97-8d0dddc64a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a756a6-0785-40d0-98d2-ca2c8fdf56d4",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "498cfa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Configuration settings defined in source file\n",
      "Training started with these settings:  Namespace(amp=False, cache_dir=None, config=None, dataset='Task09_Spleen/imagesTr', dataset_path='/workspace/abdominal-segmentation/datasets', deepgrow_probability_train=0.4, deepgrow_probability_val=1.0, epochs=20, export=False, image_interval=1, input='/workspace/abdominal-segmentation/datasets/Task09_Spleen/imagesTr', labels={'spleen': 1, 'background': 0}, learning_rate=0.0001, limit=0, local_rank=0, max_train_interactions=15, max_val_interactions=5, multi_gpu=False, network='dynunet', output='/workspace/abdominal-segmentation/models/Task09_Spleen/imagesTr', output_path='/workspace/abdominal-segmentation/models', resume=False, save_interval=3, seed=36, spatial_size=[128, 128, 128], split=0.9, use_gpu=True, val_freq=1)\n",
      "[2022-06-28 21:39:16.555][ INFO](root) - USING:: seed = 36\n",
      "[2022-06-28 21:39:16.557][ INFO](root) - USING:: network = dynunet\n",
      "[2022-06-28 21:39:16.558][ INFO](root) - USING:: input = /workspace/abdominal-segmentation/datasets/Task09_Spleen/imagesTr\n",
      "[2022-06-28 21:39:16.559][ INFO](root) - USING:: output = /workspace/abdominal-segmentation/models/Task09_Spleen/imagesTr\n",
      "[2022-06-28 21:39:16.560][ INFO](root) - USING:: use_gpu = True\n",
      "[2022-06-28 21:39:16.561][ INFO](root) - USING:: amp = False\n",
      "[2022-06-28 21:39:16.562][ INFO](root) - USING:: epochs = 20\n",
      "[2022-06-28 21:39:16.563][ INFO](root) - USING:: split = 0.9\n",
      "[2022-06-28 21:39:16.563][ INFO](root) - USING:: limit = 0\n",
      "[2022-06-28 21:39:16.564][ INFO](root) - USING:: cache_dir = None\n",
      "[2022-06-28 21:39:16.565][ INFO](root) - USING:: resume = False\n",
      "[2022-06-28 21:39:16.566][ INFO](root) - USING:: val_freq = 1\n",
      "[2022-06-28 21:39:16.567][ INFO](root) - USING:: learning_rate = 0.0001\n",
      "[2022-06-28 21:39:16.568][ INFO](root) - USING:: max_train_interactions = 15\n",
      "[2022-06-28 21:39:16.569][ INFO](root) - USING:: max_val_interactions = 5\n",
      "[2022-06-28 21:39:16.570][ INFO](root) - USING:: deepgrow_probability_train = 0.4\n",
      "[2022-06-28 21:39:16.571][ INFO](root) - USING:: deepgrow_probability_val = 1.0\n",
      "[2022-06-28 21:39:16.572][ INFO](root) - USING:: save_interval = 3\n",
      "[2022-06-28 21:39:16.573][ INFO](root) - USING:: image_interval = 1\n",
      "[2022-06-28 21:39:16.573][ INFO](root) - USING:: multi_gpu = False\n",
      "[2022-06-28 21:39:16.574][ INFO](root) - USING:: local_rank = 0\n",
      "[2022-06-28 21:39:16.575][ INFO](root) - USING:: export = False\n",
      "[2022-06-28 21:39:16.576][ INFO](root) - USING:: config = None\n",
      "[2022-06-28 21:39:16.577][ INFO](root) - USING:: dataset_path = /workspace/abdominal-segmentation/datasets\n",
      "[2022-06-28 21:39:16.578][ INFO](root) - USING:: output_path = /workspace/abdominal-segmentation/models\n",
      "[2022-06-28 21:39:16.579][ INFO](root) - USING:: dataset = Task09_Spleen/imagesTr\n",
      "[2022-06-28 21:39:16.579][ INFO](root) - USING:: spatial_size = [128, 128, 128]\n",
      "[2022-06-28 21:39:16.580][ INFO](root) - USING:: labels = {'spleen': 1, 'background': 0}\n",
      "\n",
      "[2022-06-28 21:39:16.595][ INFO](root) - CACHE_DIR IS: None\n",
      "[2022-06-28 21:39:16.596][ INFO](root) - 0:: Total Records used for Training is: 37/41\n",
      "[2022-06-28 21:39:16.597][ INFO](root) - 0:: Total Records used for Validation is: 4/41\n",
      "[2022-06-28 21:39:23.595][ INFO](ignite.engine.engine.SupervisedTrainer) - Engine run resuming from iteration 0, epoch 0 until 20 epochs\n",
      "[2022-06-28 21:39:32.073][ INFO](ignite.engine.engine.SupervisedTrainer) - Epoch: 1/20, Iter: 1/37 -- train_loss: 0.8867 \n",
      "[2022-06-28 21:39:32.890][ INFO](ignite.engine.engine.SupervisedTrainer) - Epoch: 1/20, Iter: 2/37 -- train_loss: 0.9142 \n",
      "[2022-06-28 21:39:35.949][ INFO](ignite.engine.engine.SupervisedTrainer) - Epoch: 1/20, Iter: 3/37 -- train_loss: 0.8727 \n",
      "2022-06-28 21:39:37,528 - INFO - Number of simulated clicks: 6\n",
      "[2022-06-28 21:39:38.467][ INFO](ignite.engine.engine.SupervisedTrainer) - Epoch: 1/20, Iter: 4/37 -- train_loss: 0.8538 \n",
      "[2022-06-28 21:39:39.883][ INFO](ignite.engine.engine.SupervisedTrainer) - Epoch: 1/20, Iter: 5/37 -- train_loss: 0.8142 \n",
      "[2022-06-28 21:39:43.378][ERROR](ignite.engine.engine.SupervisedTrainer) - Engine run is terminating due to exception: \n",
      "[2022-06-28 21:39:43.381][ERROR](ignite.engine.engine.SupervisedTrainer) - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 753, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 807, in _run_once_on_dataset\n",
      "    self.state.batch = next(self._dataloader_iter)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1152, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f1d5fac0fba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdatefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-e022fd90edac>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#args.model_filepath = args.output + \"/net_key_metric=0.8566.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training started with these settings: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-df04e716346a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_train_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             )\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \"\"\"\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format=\"[%(asctime)s.%(msecs)03d][%(levelname)5s](%(name)s) - %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f4d15-7365-44d1-a0f6-4c3ac1f279d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
